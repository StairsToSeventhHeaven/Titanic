{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Framework of Machine Learning\n",
    "\n",
    "Purpose:  choose (or construct) the model whose score is the best among others. \n",
    "\n",
    "0. Preprocessing (Most important and Most difficult)\n",
    "\n",
    "Dealing with the missing data.\n",
    "Feature extraction or feature selection.\n",
    "For example, what variable is relevant to prediction ? Can you make a new variable (feature) from given variables ? \n",
    "\n",
    "\n",
    "1. separate the given data into train data and test data\n",
    "\n",
    " When choosing a model, the score or the accuracy is necessary to compare a model to another.\n",
    " The ratio len(train data):len(test data) is often set to 7:3 or 8:2. (however, we must set it flexibly in terms of data size)\n",
    "\n",
    "2. candidates for model\n",
    "\n",
    " model_candidates={model_1,model_2,...,model_M}\n",
    " A model can be deep learning, SVM or XGBoost and so on.\n",
    "\n",
    " for model in {model_1,model_2,...,model_M}:\n",
    "     Do 3 and 4 as stated below.\n",
    "\n",
    "3. preparation for k-fold cross validation if you have some hyper parameters in your model\n",
    "\n",
    " k is often set to 10.(however, we must set it flexibly in terms of data size)\n",
    " We have to divide \"train data\" into k pieces roughly equally.\n",
    " (If you have 101 samples and k=10, then the length of one of ten pieces is 11.)\n",
    " Name them D_1, D_2,..., D_k.\n",
    " Candidates for hyper parameters {a_1,a_2,...,a_L}\n",
    "\n",
    " # PROCEDURE\n",
    " for alpha in {a_1,a_2,...,a_L}:\n",
    "    \n",
    "     cross_validation_score=0\n",
    "    \n",
    "     for i in {1,2,...,k}:\n",
    "       \n",
    "         train the model using alpha and {D_1,D_2,...,D_k}-{D_i}\n",
    "         test the model using alpha and D_i\n",
    "         cross_validation_score+=test score\n",
    "        \n",
    "     memorize cross_varidation_score/k (when using hyper parameter alpha)    \n",
    " # END\n",
    "\n",
    " A candidate with the highest cross_validation_score is your hyper parameter.\n",
    "\n",
    "\n",
    "4. training and test\n",
    "\n",
    " train and test your model (if any, using your hyper parameter).\n",
    "\n",
    "\n",
    "5. GOAL\n",
    "\n",
    " A model with the highest score is your model.\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy \n",
    "\n",
    "D=pd.read_csv('train.csv',index_col=0)\n",
    "test=pd.read_csv('test.csv')\n",
    "\n",
    "t=D['Survived']\n",
    "X=D.drop('Survived',axis=1)\n",
    "\n",
    "# 0. preprocessing\n",
    "\n",
    "delete_list=['Name','Ticket','Cabin','Embarked']\n",
    "X=X.drop(delete_list,axis=1)\n",
    "\n",
    "test=test.drop(delete_list,axis=1)\n",
    "passenser_id=test['PassengerId']\n",
    "test=test.drop('PassengerId',axis=1)\n",
    "test=np.array(test)\n",
    "\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "X=np.array(X)\n",
    "t=np.array(t)\n",
    "for i in range(np.shape(X)[0]):\n",
    "    \n",
    "    if X[i,1]=='male':\n",
    "        X[i,1]=1\n",
    "        \n",
    "    else:\n",
    "        X[i,1]=0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    if test[i,1]=='male':\n",
    "        test[i,1]=1\n",
    "    else:\n",
    "        test[i,1]=0\n",
    "        \n",
    "        \n",
    "X=np.asarray(X,dtype=float)                        \n",
    "test=np.asarray(test,dtype=float)                \n",
    "\n",
    "# mean substitution\n",
    "\n",
    "X_mean=np.nanmean(X,axis=0)\n",
    "        \n",
    "for i in range(np.shape(X)[0]):\n",
    "    for j in range(np.shape(X)[1]):\n",
    "        if np.isnan(X[i,j]):\n",
    "            X[i,j]=X_mean[j]\n",
    "\n",
    "for i in range(np.shape(test)[0]):\n",
    "    for j in range(np.shape(test)[1]):\n",
    "        if np.isnan(test[i,j]):\n",
    "            test[i,j]=X_mean[j]            \n",
    "\n",
    "#print(X[1:10]) \n",
    "#print(test[0:10])\n",
    "X=scipy.stats.zscore(X)\n",
    "test=scipy.stats.zscore(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. separate the given data into train data and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_ratio=0.2\n",
    "X_train, X_test, t_train, t_test =train_test_split(X, t, test_size=test_ratio,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. candidates for models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GaussianNB()\n",
    "model.fit(X_train,t_train)\n",
    "print(model.score(X_train,t_train))\n",
    "print(model.score(X_test,t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. preparation for k-fold cross validation if you have some hyper parameters in your model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "split_size=10\n",
    "k_fold=KFold(n_splits=split_size,shuffle=True)\n",
    "\n",
    "train_v=[]\n",
    "test_v=[]\n",
    "\n",
    "for train_indices, validation_indices in k_fold.split(X_train):\n",
    "    train_v.append(train_indices)\n",
    "    test_v.append(validation_indices)\n",
    "        \n",
    "validation_score=-100\n",
    "hyperpara_opt=0\n",
    "for alpha in {0.001,0.01,0.1,1,10,100,1000}:\n",
    "    \n",
    "    validation_score_sum=0\n",
    "    model=LogisticRegression(C=alpha,solver='lbfgs',max_iter=10000) \n",
    "   \n",
    "    for i in range(split_size):\n",
    "    \n",
    "        model.fit(X_train[train_v[i]],t_train[train_v[i]])\n",
    "        validation_score_sum+=model.score(X_train[test_v[i]],t_train[test_v[i]])\n",
    "        \n",
    "    if validation_score_sum/split_size>validation_score:\n",
    "        validation_score=validation_score_sum/split_size\n",
    "        hyperpara_opt=alpha        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. trainin and test\n",
    "model=LogisticRegression(C=hyperpara_opt,solver='lbfgs',max_iter=10000)\n",
    "model.fit(X_train,t_train)\n",
    "print('score:',model.score(X_test,t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame(index=passenser_id)\n",
    "pred=model.predict(test)\n",
    "output['Survived']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(hidden_layer_sizes=(100,100),alpha=0.001,max_iter=1000000,activation='relu')\n",
    "model.fit(X_train,t_train)\n",
    "print(model.score(X_train,t_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(C=10,kernel='rbf',gamma='auto',degree=2)\n",
    "model.fit(X_train,t_train)\n",
    "model.score(X_test,t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train,t_train)\n",
    "model.score(X_test,t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
